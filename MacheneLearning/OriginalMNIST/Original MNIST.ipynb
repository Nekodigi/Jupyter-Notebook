{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleDNN\n",
    "### import & dataSetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#dataSetup\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train = x_train / 255\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = x_test / 255\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, input_dim=100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 1.4107 - accuracy: 0.5480 - val_loss: 0.6556 - val_accuracy: 0.8491\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.4871 - accuracy: 0.8768 - val_loss: 0.3625 - val_accuracy: 0.9091\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.3226 - accuracy: 0.9147 - val_loss: 0.2727 - val_accuracy: 0.9282\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.2517 - accuracy: 0.9315 - val_loss: 0.2261 - val_accuracy: 0.9407\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.2110 - accuracy: 0.9415 - val_loss: 0.1968 - val_accuracy: 0.9437\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.1823 - accuracy: 0.9489 - val_loss: 0.1743 - val_accuracy: 0.9495\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1608 - accuracy: 0.9551 - val_loss: 0.1579 - val_accuracy: 0.9536\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1449 - accuracy: 0.9592 - val_loss: 0.1474 - val_accuracy: 0.9572\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 0.1318 - accuracy: 0.9627 - val_loss: 0.1376 - val_accuracy: 0.9606\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 0.1210 - accuracy: 0.9657 - val_loss: 0.1294 - val_accuracy: 0.9629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2151be28688>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=1000,\n",
    "         verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid\n",
    "mid=100 0.9292<br>\n",
    "mid=10 0.8598\n",
    "#### ReLU\n",
    "mid=100 0.9601\n",
    "mid=10 0.9167"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Conv\n",
    "### import & dataSetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (n, n), padding='same',\n",
    "                input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.8798 - accuracy: 0.7975 - val_loss: 0.3580 - val_accuracy: 0.8994\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3204 - accuracy: 0.9082 - val_loss: 0.2665 - val_accuracy: 0.9267\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2459 - accuracy: 0.9307 - val_loss: 0.2081 - val_accuracy: 0.9424\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1935 - accuracy: 0.9460 - val_loss: 0.1700 - val_accuracy: 0.9539\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1560 - accuracy: 0.9573 - val_loss: 0.1436 - val_accuracy: 0.9607\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1314 - accuracy: 0.9642 - val_loss: 0.1208 - val_accuracy: 0.9671\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1143 - accuracy: 0.9689 - val_loss: 0.1076 - val_accuracy: 0.9700\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1001 - accuracy: 0.9727 - val_loss: 0.0988 - val_accuracy: 0.9728\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0904 - accuracy: 0.9758 - val_loss: 0.0914 - val_accuracy: 0.9746\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0833 - accuracy: 0.9775 - val_loss: 0.0873 - val_accuracy: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21510c4fcc8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=1000, epochs=10,\n",
    "         verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9751\n",
    "0.9851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x180 with 17 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(1, figsize=(12, 2.5))\n",
    "plt.gray()\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "plt.subplot(2, 9, 10)\n",
    "id_img = 12\n",
    "x_img = x_test[id_img, :, :, 0]\n",
    "img_h = 28\n",
    "img_w = 28\n",
    "x_img = x_img.reshape(img_h, img_w)\n",
    "plt.pcolor(-x_img)\n",
    "plt.xlim(0, img_h)\n",
    "plt.ylim(img_w, 0)\n",
    "plt.xticks([], \"\")\n",
    "plt.yticks([], \"\")\n",
    "plt.title(\"Original\")\n",
    "\n",
    "w = model.layers[0].get_weights()[0]\n",
    "max_w = np.max(w)\n",
    "min_w = np.min(w)\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 9, i + 2)\n",
    "    w1 = w[:, :, 0, i]\n",
    "    w1 = w1.reshape(n, n)\n",
    "    plt.pcolor(-w1, vmin=min_w, vmax=max_w)\n",
    "    plt.xlim(0, n)\n",
    "    plt.ylim(n, 0)\n",
    "    plt.xticks([], \"\")\n",
    "    plt.yticks([], \"\")\n",
    "    plt.title(\"%d\" % i)\n",
    "    plt.subplot(2, 9, i + 11)\n",
    "    out_img = np.zeros_like(x_img)\n",
    "    for ih in range(img_h - n):\n",
    "        for iw in range(img_w - n):\n",
    "            img_part = x_img[ih:ih + n, iw:iw + n]\n",
    "            out_img[ih + 1, iw + 1] = \\\n",
    "            np.dot(img_part.reshape(-1), w1.reshape(-1))\n",
    "    plt.pcolor(-out_img)\n",
    "    plt.xlim(0, img_w)\n",
    "    plt.ylim(img_h, 0)\n",
    "    plt.xticks([], \"\")\n",
    "    plt.yticks([], \"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Encode\n",
    "### import & dataSetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataSetup\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train = x_train / 255\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = x_test / 255\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=784, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(36, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(784, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.3600 - accuracy: 0.7520 - val_loss: 0.2538 - val_accuracy: 0.7941\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2294 - accuracy: 0.7940 - val_loss: 0.2041 - val_accuracy: 0.7942\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1879 - accuracy: 0.7977 - val_loss: 0.1699 - val_accuracy: 0.8003\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1624 - accuracy: 0.8026 - val_loss: 0.1521 - val_accuracy: 0.8033\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1473 - accuracy: 0.8057 - val_loss: 0.1400 - val_accuracy: 0.8054\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1379 - accuracy: 0.8075 - val_loss: 0.1327 - val_accuracy: 0.8078\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1318 - accuracy: 0.8086 - val_loss: 0.1281 - val_accuracy: 0.8087\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1281 - accuracy: 0.8092 - val_loss: 0.1247 - val_accuracy: 0.8084\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1252 - accuracy: 0.8096 - val_loss: 0.1223 - val_accuracy: 0.8083\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1220 - accuracy: 0.8102 - val_loss: 0.1189 - val_accuracy: 0.8095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2151272d648>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, x_train, epochs=10, batch_size=1000,\n",
    "         verbose=1, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8822e7f89359>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimage_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m encoder.compile(optimizer='adam',\n\u001b[0;32m      8\u001b[0m                     loss='binary_crossentropy')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "image_height = 28\n",
    "image_width = 28\n",
    "\n",
    "encoder = models.clone_model(model)\n",
    "encoder.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy')\n",
    "encoder.set_weights(model.get_weights())\n",
    "# 最終段のレイヤーを取り除く\n",
    "encoder.pop()\n",
    "encoder.pop()\n",
    "encoder.pop()\n",
    "\n",
    "p = np.random.random_integers(0, len(x_test), 10)\n",
    "x_test_sampled = x_test[p]\n",
    "x_test_sampled_pred = model.predict_proba(x_test_sampled,\n",
    "                                              verbose=0)\n",
    "x_test_sampled_enc = encoder.predict_proba(x_test_sampled,\n",
    "                                               verbose=0)\n",
    "\n",
    "fig, axes = plt.subplots(3, 10)\n",
    "for i, label in enumerate(y_test[p]):\n",
    "    # 元画像を上段に表示する\n",
    "    img = x_test_sampled[i].reshape(image_height, image_width)\n",
    "    axes[0][i].imshow(img, cmap=cm.gray_r)\n",
    "    axes[0][i].axis('off')\n",
    "    axes[0][i].set_title(label, color='red')\n",
    "    # AutoEncoder で次元圧縮した画像を下段に表示する\n",
    "    enc_img = x_test_sampled_enc[i].reshape(6, 6)\n",
    "    axes[1][i].imshow(enc_img, cmap=cm.gray_r)\n",
    "    axes[1][i].axis('off')\n",
    "    #AutoEncoder で復元した画像を下段に表示する\n",
    "    pred_img = x_test_sampled_pred[i].reshape(image_height, image_width)\n",
    "    axes[2][i].imshow(pred_img, cmap=cm.gray_r)\n",
    "    axes[2][i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import callbacks\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "def main():\n",
    "    # MNIST データセットを読み込む\n",
    "    (x_train, train), (x_test, y_test) = mnist.load_data()\n",
    "    image_height, image_width = 28, 28\n",
    "    # 中間層で圧縮される次元数\n",
    "    encoding_dim = 36  # 中間層の出力を 6 x 6 の画像として可視化するため\n",
    "\n",
    "    # Flatten\n",
    "    x_train = x_train.reshape(x_train.shape[0], image_height * image_width)\n",
    "    x_test = x_test.reshape(x_test.shape[0], image_height * image_width)\n",
    "\n",
    "    # Min-Max Normalization\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train = (x_train - x_train.min()) / (x_train.max() - x_train.min())\n",
    "    x_test = (x_test - x_test.min()) / (x_test.max() - x_test.min())\n",
    "\n",
    "    # 中間層が一層だけの単純な AutoEncoder\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(encoding_dim, activation='relu',\n",
    "                           input_shape=(image_height * image_width,)))\n",
    "    model.add(layers.Dense(image_height * image_width,\n",
    "                           activation='sigmoid'))\n",
    "\n",
    "    # モデルの構造を確認する\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy')\n",
    "\n",
    "    fit_callbacs = [\n",
    "        callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                patience=5,\n",
    "                                mode='min')\n",
    "    ]\n",
    "\n",
    "    # モデルを学習させる\n",
    "    model.fit(x_train, x_train,\n",
    "              epochs=10,\n",
    "              batch_size=256,\n",
    "              shuffle=True,\n",
    "              validation_data=(x_test, x_test),\n",
    "              callbacks=fit_callbacs,\n",
    "              )\n",
    "\n",
    "    # テストデータの損失を確認しておく\n",
    "    score = model.evaluate(x_test, x_test, verbose=0)\n",
    "    print('test xentropy:', score)\n",
    "\n",
    "    # 学習済みのモデルを元に、次元圧縮だけするモデルを用意する\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    # 最終段のレイヤーを取り除く\n",
    "    encoder.pop()\n",
    "\n",
    "    # テストデータからランダムに 10 点を選び出す\n",
    "    p = np.random.random_integers(0, len(x_test), 10)\n",
    "    x_test_sampled = x_test[p]\n",
    "    # 選びだしたサンプルを AutoEncoder にかける\n",
    "    x_test_sampled_pred = model.predict_proba(x_test_sampled,\n",
    "                                              verbose=0)\n",
    "    # 次元圧縮だけする場合\n",
    "    x_test_sampled_enc = encoder.predict_proba(x_test_sampled,\n",
    "                                               verbose=0)\n",
    "\n",
    "    # 処理結果を可視化する\n",
    "    fig, axes = plt.subplots(3, 10)\n",
    "    for i, label in enumerate(y_test[p]):\n",
    "        # 元画像を上段に表示する\n",
    "        img = x_test_sampled[i].reshape(image_height, image_width)\n",
    "        axes[0][i].imshow(img, cmap=cm.gray_r)\n",
    "        axes[0][i].axis('off')\n",
    "        axes[0][i].set_title(label, color='red')\n",
    "        # AutoEncoder で次元圧縮した画像を下段に表示する\n",
    "        enc_img = x_test_sampled_enc[i].reshape(6, 6)\n",
    "        axes[1][i].imshow(enc_img, cmap=cm.gray_r)\n",
    "        axes[1][i].axis('off')\n",
    "        # AutoEncoder で復元した画像を下段に表示する\n",
    "        pred_img = x_test_sampled_pred[i].reshape(image_height, image_width)\n",
    "        axes[2][i].imshow(pred_img, cmap=cm.gray_r)\n",
    "        axes[2][i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### -*-coding:utf-8-*-\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Convolution2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class DCGAN():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.path = \"/volumes/data/dataset/gan/MNIST/dcgan/dcgan_generated_images/\"\n",
    "        #mnistデータ用の入力データサイズ\n",
    "        self.img_rows = 28 \n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        # 潜在変数の次元数 \n",
    "        self.z_dim = 5\n",
    "\n",
    "        # 画像保存の際の列、行数\n",
    "        self.row = 5\n",
    "        self.col = 5\n",
    "        self.row2 = 1 # 連続潜在変数用\n",
    "        self.col2 = 10# 連続潜在変数用 \n",
    "        \n",
    "        # 画像生成用の固定された入力潜在変数\n",
    "        self.noise_fix1 = np.random.normal(0, 1, (self.row * self.col, self.z_dim)) \n",
    "        # 連続的に潜在変数を変化させる際の開始、終了変数\n",
    "        self.noise_fix2 = np.random.normal(0, 1, (1, self.z_dim))\n",
    "        self.noise_fix3 = np.random.normal(0, 1, (1, self.z_dim))\n",
    "\n",
    "        # 横軸がiteration数のプロット保存用np.ndarray\n",
    "        self.g_loss_array = np.array([])\n",
    "        self.d_loss_array = np.array([])\n",
    "        self.d_accuracy_array = np.array([])\n",
    "        self.d_predict_true_num_array = np.array([])\n",
    "        self.c_predict_class_list = []\n",
    "\n",
    "        discriminator_optimizer = Adam(lr=1e-5, beta_1=0.1)\n",
    "        combined_optimizer = Adam(lr=2e-4, beta_1=0.5)\n",
    "\n",
    "        # discriminatorモデル\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', \n",
    "            optimizer=discriminator_optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Generatorモデル\n",
    "        self.generator = self.build_generator()\n",
    "        # generatorは単体で学習しないのでコンパイルは必要ない\n",
    "        #self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        self.combined = self.build_combined1()\n",
    "        #self.combined = self.build_combined2()\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=combined_optimizer)\n",
    "\n",
    "        # Classifierモデル\n",
    "        self.classifier = self.build_classifier()\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(1024, input_shape=noise_shape))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(128*7*7))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Reshape((7,7,128), input_shape=(128*7*7,)))\n",
    "        model.add(UpSampling2D((2,2)))\n",
    "        model.add(Convolution2D(64,5,5,border_mode='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(UpSampling2D((2,2)))\n",
    "        model.add(Convolution2D(1,5,5,border_mode='same'))\n",
    "        model.add(Activation('tanh'))\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(64,5,5, subsample=(2,2),\\\n",
    "                  border_mode='same', input_shape=img_shape))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(Convolution2D(128,5,5,subsample=(2,2)))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))   \n",
    "        return model\n",
    "    \n",
    "    def build_combined1(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        return model\n",
    "\n",
    "    def build_combined2(self):\n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        valid = self.discriminator(img)\n",
    "        model = Model(z, valid)\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def build_classifier(self):\n",
    "        model = load_model(\"cnn_model.h5\")\n",
    "        model.load_weights('cnn_weight.h5')\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # mnistデータの読み込み\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # 値を-1 to 1に規格化\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        self.g_loss_array = np.zeros(epochs)\n",
    "        self.d_loss_array = np.zeros(epochs)\n",
    "        self.d_accuracy_array = np.zeros(epochs)\n",
    "        self.d_predict_true_num_array = np.zeros(epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Discriminatorの学習\n",
    "            # ---------------------\n",
    "\n",
    "            # バッチサイズの半数をGeneratorから生成\n",
    "            noise = np.random.normal(0, 1, (half_batch, self.z_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "\n",
    "            # バッチサイズの半数を教師データからピックアップ\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # discriminatorを学習\n",
    "            # 本物データと偽物データは別々に学習させる\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            # それぞれの損失関数を平均\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # discriminatorの予測（本物と偽物が半々のミニバッチ）\n",
    "            d_predict = self.discriminator.predict_classes(np.concatenate([gen_imgs,imgs]), verbose=0)\n",
    "            d_predict = np.sum(d_predict)\n",
    "\n",
    "# classifierの予測\n",
    "            c_predict = self.classifier.predict_classes(np.concatenate([gen_imgs,imgs]), verbose=0)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Generatorの学習\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "\n",
    "\n",
    "            # 生成データの正解ラベルは本物（1） \n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "\n",
    "            # 進捗の表示\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # np.ndarrayにloss関数を格納\n",
    "            self.g_loss_array[epoch] = g_loss\n",
    "            self.d_loss_array[epoch] = d_loss[0]\n",
    "            self.d_accuracy_array[epoch] = 100*d_loss[1]\n",
    "            self.d_predict_true_num_array[epoch] = d_predict\n",
    "            self.c_predict_class_list.append(c_predict)\n",
    "\n",
    "            if epoch % save_interval == 0:\n",
    "                \n",
    "                # 毎回異なる乱数から画像を生成\n",
    "                self.save_imgs(self.row, self.col, epoch, '', noise)\n",
    "                # 毎回同じ値から画像を生成\n",
    "                self.save_imgs(self.row, self.col, epoch, 'fromFixedValue', self.noise_fix1)\n",
    "                # 二つの潜在変数の間の遷移画像を生成\n",
    "                total_images = self.row*self.col\n",
    "                noise_trans = np.zeros((total_images, self.z_dim))\n",
    "                for i in range(total_images):\n",
    "                    t = (i*1.)/((total_images-1)*1.)\n",
    "                    noise_trans[i,:] = t * self.noise_fix2 + (1-t) * self.noise_fix3\n",
    "                self.save_imgs(self.row2, self.col2, epoch, 'trans', noise_trans)\n",
    "\n",
    "                # classifierに生成画像のクラス識別をさせる（10000サンプル）\n",
    "                noise = np.random.normal(0, 1, (10000, self.z_dim))\n",
    "                class_res = self.classifier.predict_classes(self.generator.predict(noise), verbose=0)\n",
    "                # plot histgram\n",
    "                plt.hist(class_res)\n",
    "                plt.savefig(self.path + \"mnist_hist_%d.png\" % epoch)\n",
    "                plt.ylim(0,2000)\n",
    "                plt.close()\n",
    "\n",
    "\n",
    "       \n",
    "                # 学習結果をプロット\n",
    "                fig, ax = plt.subplots(4,1, figsize=(8.27,11.69))\n",
    "                ax[0].plot(self.g_loss_array[:epoch])\n",
    "                ax[0].set_title(\"g_loss\")\n",
    "                ax[1].plot(self.d_loss_array[:epoch])\n",
    "                ax[1].set_title(\"d_loss\")\n",
    "                ax[2].plot(self.d_accuracy_array[:epoch])\n",
    "                ax[2].set_title(\"d_accuracy\")\n",
    "                ax[3].plot(self.d_predict_true_num_array[:epoch])\n",
    "                ax[3].set_title(\"d_predict_true_num_array\")\n",
    "                fig.suptitle(\"epoch: %5d\" % epoch)\n",
    "                fig.savefig(self.path + \"training_%d.png\" % epoch)\n",
    "                plt.close()\n",
    "\n",
    "        # 重みを保存\n",
    "        self.generator.save_weights(self.path + \"generator_%s.h5\" % epoch)\n",
    "        self.discriminator.save_weights(self.path + \"discriminator_%s.h5\" % epoch)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    def save_imgs(self, row, col, epoch, filename, noise):\n",
    "        # row, col\n",
    "        # 生成画像を敷き詰めるときの行数、列数\n",
    "    \n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "    \n",
    "        # 生成画像を0-1に再スケール\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "    \n",
    "    \n",
    "        fig, axs = plt.subplots(row, col)\n",
    "        cnt = 0\n",
    "        if row == 1:\n",
    "            for j in range(col):\n",
    "                axs[j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[j].axis('off')\n",
    "                cnt += 1\n",
    "        else:\n",
    "            for i in range(row):\n",
    "                for j in range(col):\n",
    "                    axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                    axs[i,j].axis('off')\n",
    "                    cnt += 1\n",
    "\n",
    "        #fig.savefig(\"images/mnist_%s_%d.png\" % (filename, epoch))\n",
    "        fig.suptitle(\"epoch: %5d\" % epoch)\n",
    "        fig.savefig(self.path + \"mnist_%s_%d.png\" % (filename, epoch))\n",
    "        plt.close()\n",
    "    \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    gan = DCGAN()\n",
    "    gan.train(epochs=100000, batch_size=32, save_interval=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
