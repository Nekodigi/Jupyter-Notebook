{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [0.8, 0.5, 1.0]\n",
    "\n",
    "gamma = 0.95\n",
    "\n",
    "r = np.zeros((3, 3, 2))\n",
    "r[0, 1, 0] = 1.0\n",
    "r[0, 2, 0] = 2.0\n",
    "r[0, 0, 1] = 0.0\n",
    "r[1, 0, 0] = 1.0\n",
    "r[1, 2, 0] = 2.0\n",
    "r[1, 1, 1] = 1.0\n",
    "r[2, 0, 0] = 1.0\n",
    "r[2, 1, 0] = 0.0\n",
    "r[2, 2, 1] = -1.0\n",
    "\n",
    "v = [0, 0, 0]\n",
    "v_prev = copy.copy(v)\n",
    "\n",
    "q = np.zeros((3, 2))\n",
    "\n",
    "pi = [0.5, 0.5, 0.5]\n",
    "\n",
    "def policy_estimator(pi, p, r, gamma):\n",
    "    R = [0, 0, 0]\n",
    "    P = np.zeros((3, 3))\n",
    "    A = np.zeros((3, 3))\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        P[i, i] = 1 - pi[i]\n",
    "        P[i, (i + 1) % 3] = p[i] * pi[i]\n",
    "        P[i, (i + 2) % 3] = (1 - p[i]) * pi[i]\n",
    "        \n",
    "        R[i] = pi[i] * (p[i] * r[i, (i + 1) % 3, 0] + (1 - p[i]) * r[i, (i + 2) % 3, 0]) + (1 - pi[i]) * r[i, i, 1]\n",
    "            \n",
    "    A = np.eye(3) - gamma * P\n",
    "    B = np.linalg.inv(A)\n",
    "    v_sol = np.dot(B, R)\n",
    "    \n",
    "    return v_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 value: [13.48232426 13.99837464 12.19829338] policy: [0.5, 0.5, 0.5]\n",
      "step: 1 value: [20.24405125 20.         20.23184869] policy: [1, 0, 1]\n",
      "step: 2 value: [25.01947209 25.14928602 24.76849849] policy: [1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for step in range(100):\n",
    "    \n",
    "    v = policy_estimator(pi, p, r, gamma)\n",
    "    \n",
    "    if np.min(v - v_prev) <= 0:\n",
    "        break\n",
    "        \n",
    "    print('step:', step, 'value:', v, 'policy:', pi)\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        q[i, 0] = p[i] * (r[i, (i + i) % 3, 0] + gamma * v[(i + i) % 3]) + (1 - p[i]) * (r[i, (i + 2) % 3, 0] + gamma * v[(i + 2) % 3])\n",
    "        q[i, 1] = r[i, i, 1] + gamma * v[i]\n",
    "        \n",
    "        if q[i, 0] > q[i, 1]:\n",
    "            pi[i] = 1\n",
    "        elif q[i, 0] == q[i, 1]:\n",
    "            pi[i] = 0.5\n",
    "        else:\n",
    "            pi[i] = 0\n",
    "            \n",
    "    v_prev = copy.copy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  value: [13.48232426 13.99837464 12.19829338]  policy: [0.5, 0.5, 0.5]\n",
      "step: 1  value: [20.24405125 20.         20.23184869]  policy: [1, 0, 1]\n",
      "step: 2  value: [25.01947209 25.14928602 24.76849849]  policy: [1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "overview:\n",
    "    方策反復法により３状態２行動のマルコフ決定過程を解く\n",
    "\n",
    "args:\n",
    "    各種パラメータ設定値は、本コード中に明記される\n",
    "\n",
    "output:\n",
    "    反復ステップごとに３状態の価値関数値および方策確率を出力\n",
    "\n",
    "usage-example:\n",
    "    python3 policy_iteraton.py\n",
    "\"\"\"\n",
    "# 各種モジュールのインポート\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# MDP の設定\n",
    "p = [0.8, 0.5, 1.0]\n",
    "\n",
    "# 割引率の設定\n",
    "gamma = 0.95\n",
    "\n",
    "# 報酬期待値の設定\n",
    "r = np.zeros((3, 3, 2))\n",
    "r[0, 1, 0] = 1.0\n",
    "r[0, 2, 0] = 2.0\n",
    "r[0, 0, 1] = 0.0\n",
    "r[1, 0, 0] = 1.0\n",
    "r[1, 2, 0] = 2.0\n",
    "r[1, 1, 1] = 1.0\n",
    "r[2, 0, 0] = 1.0\n",
    "r[2, 1, 0] = 0.0\n",
    "r[2, 2, 1] = -1.0\n",
    "\n",
    "# 価値関数の初期化\n",
    "v = [0, 0, 0]\n",
    "v_prev = copy.copy(v)\n",
    "\n",
    "# 行動価値関数の初期化\n",
    "q = np.zeros((3, 2))\n",
    "\n",
    "# 方策分布の初期化\n",
    "pi = [0.5, 0.5, 0.5]\n",
    "\n",
    "\n",
    "# 方策評価関数の定義\n",
    "def policy_estimator(pi, p, r, gamma):\n",
    "    # 初期化\n",
    "    R = [0, 0, 0]\n",
    "    P = np.zeros((3, 3))\n",
    "    A = np.zeros((3, 3))\n",
    "\n",
    "    for i in range(3):\n",
    "\n",
    "        # 状態遷移行列の計算\n",
    "        P[i, i] = 1 - pi[i]\n",
    "        P[i, (i + 1) % 3] = p[i] * pi[i]\n",
    "        P[i, (i + 2) % 3] = (1 - p[i]) * pi[i]\n",
    "\n",
    "        # 報酬ベクトルの計算\n",
    "        R[i] = pi[i] * (p[i] * r[i, (i + 1) % 3, 0] +\n",
    "                        (1 - p[i]) * r[i, (i + 2) % 3, 0]\n",
    "                        ) + (1 - pi[i]) * r[i, i, 1]\n",
    "\n",
    "    # 行列計算によるベルマン方程式の求解\n",
    "    A = np.eye(3) - gamma * P\n",
    "    B = np.linalg.inv(A)\n",
    "    v_sol = np.dot(B, R)\n",
    "\n",
    "    return v_sol\n",
    "\n",
    "\n",
    "# 方策反復法の計算\n",
    "for step in range(100):\n",
    "\n",
    "    # 方策評価ステップ\n",
    "    v = policy_estimator(pi, p, r, gamma)\n",
    "\n",
    "    # 価値関数 v が前ステップの値 v_prep を改善しなければ終了\n",
    "    if np.min(v - v_prev) <= 0:\n",
    "        break\n",
    "\n",
    "    # 現ステップの価値関数と方策を表示\n",
    "    print('step:', step, ' value:', v, ' policy:', pi)\n",
    "\n",
    "    # 方策改善ステップ\n",
    "    for i in range(3):\n",
    "\n",
    "        # 行動価値関数を計算\n",
    "        q[i, 0] = p[i] * (\n",
    "            r[i, (i + 1) % 3, 0] + gamma * v[(i + 1) % 3]\n",
    "        ) + (1 - p[i]) * (r[i, (i + 2) % 3, 0]\n",
    "                          + gamma * v[(i + 2) % 3])\n",
    "        q[i, 1] = r[i, i, 1] + gamma * v[i]\n",
    "\n",
    "        # 行動価値関数のもとで greedy に方策を改善\n",
    "        if q[i, 0] > q[i, 1]:\n",
    "            pi[i] = 1\n",
    "        elif q[i, 0] == q[i, 1]:\n",
    "            pi[i] = 0.5\n",
    "        else:\n",
    "            pi[i] = 0\n",
    "\n",
    "    # 現ステップの価値関数を記録\n",
    "    v_prev = copy.copy(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
